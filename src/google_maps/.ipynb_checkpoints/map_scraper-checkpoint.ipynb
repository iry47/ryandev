{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8d5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409f0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "places_path = './src/savedPlaces.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12200d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup_file(file):\n",
    "    source = './'+file+'.json'\n",
    "    destination = './backups/'+file+'/'+file+'_' + datetime.today().strftime('%Y_%m_%d_%H%M') + '.json'\n",
    "    shutil.copy(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1aa645",
   "metadata": {},
   "source": [
    "### Google maps scraper\n",
    "Source: # https://scrapfly.io/blog/how-to-scrape-google-maps/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8abb64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsel import Selector\n",
    "from playwright.async_api import async_playwright\n",
    "from playwright_stealth import stealth_async\n",
    "\n",
    "script = \"\"\"\n",
    "function waitCss(selector, n=1, require=false, timeout=5000) {\n",
    "  console.log(selector, n, require, timeout);\n",
    "  var start = Date.now();\n",
    "  while (Date.now() - start < timeout){\n",
    "  \tif (document.querySelectorAll(selector).length >= n){\n",
    "      return document.querySelectorAll(selector);\n",
    "    }\n",
    "  }\n",
    "  if (require){\n",
    "      throw new Error(`selector \"${selector}\" timed out in ${Date.now() - start} ms`);\n",
    "  } else {\n",
    "      return document.querySelectorAll(selector);\n",
    "  }\n",
    "}\n",
    "\n",
    "var results = waitCss(\"div[role*=article]>a\", n=10, require=false);\n",
    "return Array.from(results).map((el) => el.getAttribute(\"href\"))\n",
    "\"\"\"\n",
    "places_file = open(places_path)\n",
    "markers = json.load(places_file)\n",
    "\n",
    "async def search(query, page):\n",
    "    url = f\"https://www.google.com/maps/search/{query.replace(' ', '+')}/?hl=en\"\n",
    "    await page.goto(url)\n",
    "    urls = await page.evaluate(\"() => {\" + script + \"}\")\n",
    "    return urls or [url]\n",
    "\n",
    "def parse_place(selector):\n",
    "    \"\"\"parse Google Maps place\"\"\"\n",
    "\n",
    "    def aria_with_label(label):\n",
    "        \"\"\"gets aria element as is\"\"\"\n",
    "        return selector.css(f\"*[aria-label*='{label}']::attr(aria-label)\")\n",
    "\n",
    "    def aria_no_label(label):\n",
    "        \"\"\"gets aria element as text with label stripped off\"\"\"\n",
    "        text = aria_with_label(label).get(\"\")\n",
    "        return text.split(label, 1)[1].strip()\n",
    "\n",
    "    result = {\n",
    "        \"category\": selector.css(\"button[jsaction='pane.rating.category']::text\").get(),\n",
    "        # most of the data can be extracted through accessibility labels:\n",
    "        \"website\": aria_no_label(\"Website: \"),\n",
    "        \"phone\": aria_no_label(\"Phone: \"),\n",
    "        \"review_count\": aria_with_label(\" reviews\").get(),\n",
    "        # to extract star numbers from text we can use regex pattern for numbers: \"\\d+\"\n",
    "        \"stars\": aria_with_label(\" stars\").re(\"\\d+.*\\d+\")[0],\n",
    "        \"5_stars\": aria_with_label(\"5 stars\").re(r\"(\\d+) review\")[0],\n",
    "        \"4_stars\": aria_with_label(\"4 stars\").re(r\"(\\d+) review\")[0],\n",
    "        \"3_stars\": aria_with_label(\"3 stars\").re(r\"(\\d+) review\")[0],\n",
    "        \"2_stars\": aria_with_label(\"2 stars\").re(r\"(\\d+) review\")[0],\n",
    "        \"1_stars\": aria_with_label(\"1 stars\").re(r\"(\\d+) review\")[0],\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "async def scrape_google_maps():\n",
    "    '''\n",
    "    Scrape google maps\n",
    "    :return Dataframe of places\n",
    "    '''\n",
    "    places = []\n",
    "    index_error = []\n",
    "    type_error = []\n",
    "    other_error = []\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "        page = await browser.new_page()\n",
    "        for marker in markers['features']:\n",
    "            try:\n",
    "                urls = await search(marker['properties']['Title'] +' '+ marker['properties']['Location']['Address'], page=page)\n",
    "                await stealth_async(page)\n",
    "                await page.goto(urls[0])\n",
    "                await page.wait_for_selector(\"button[jsaction='pane.rating.category']\")\n",
    "                content = await page.content()\n",
    "                parsed_info = parse_place(Selector(text=content.encode('utf-8', 'ignore').decode()))\n",
    "\n",
    "                place = {\n",
    "                    \"name\": marker['properties']['Title'],\n",
    "                    \"category\": parsed_info['category'],\n",
    "                    \"google_link\": marker['properties']['Google Maps URL'],\n",
    "                    \"phone\": parsed_info['phone'],\n",
    "                    \"website\": parsed_info['website']\n",
    "\n",
    "                }\n",
    "                places.append(place)\n",
    "\n",
    "            except IndexError:\n",
    "                index_error.append(marker['properties']['Title'])\n",
    "                continue\n",
    "            except TypeError:\n",
    "                type_error.append(marker['properties']['Title'])\n",
    "                continue\n",
    "            except:\n",
    "                other_error.append(marker['properties']['Title'])\n",
    "                continue\n",
    "            \n",
    "            if len(places) == 3:\n",
    "                return pd.DataFrame.from_records(places)\n",
    "            \n",
    "            backup_file('parsed_places')\n",
    "#             df_places.to_json('parsed_places.json')\n",
    "    return pd.DataFrame.from_records(places)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8f4113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_places = await scrape_google_maps()\n",
    "# df_places = pd.read_json('./')\n",
    "len(df_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a0a42fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total markers from google 741\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total markers from google {len(markers['features'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66157b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Errors:153 Type Errors:63 Other Errors:319\n"
     ]
    }
   ],
   "source": [
    "print(f\"Index Errors:{len(index_error)} Type Errors:{len(type_error)} Other Errors:{len(other_error)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb93ff",
   "metadata": {},
   "source": [
    "## Data Engineering\n",
    "The following will set up the data to be used by the frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "660dae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_category = ['restaurant', 'cafe', 'bistro']\n",
    "hostel_category = ['hostel', 'hotel', 'bed']\n",
    "tourism_category = ['tourism', 'museum']\n",
    "outdoors_category = ['park', 'lake', 'river', 'waterfall', 'activity']\n",
    "other_category = []\n",
    "# TODO: re-scrap data and compare category guesses with list of unique categories from google\n",
    "\n",
    "\n",
    "places = open(places_path)\n",
    "df_places.to_json('parsed_places.json') # will overwrite file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1652c3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique categories from google 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique categories from google {len(df_places.category.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "913a0ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Iter through rows of places and add marker icon to place\n",
    "'''\n",
    "for ind, place in df_places.iterrows():\n",
    "    if any(cat in place.category for cat in food_category):\n",
    "        df_places[df_places['name'] == place.name]['marker'] = 'food'\n",
    "        print(place.marker)\n",
    "    elif any(cat in place.category for cat in hostel_category):\n",
    "        df_places[df_places['name'] == place.name]['marker'] = 'hostel'\n",
    "    elif any(cat in place.category for cat in tourism_category):\n",
    "        df_places[df_places['name'] == place.name]['marker'] = 'tourism'\n",
    "    elif any(cat in place.category for cat in outdoors_category):\n",
    "        df_places[df_places['name'] == place.name]['marker'] = 'outdoors'\n",
    "    else:\n",
    "        df_places[df_places['name'] == place.name]['marker'] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c100a5f",
   "metadata": {},
   "source": [
    "## Data API Merge\n",
    "Add the webscraped data to the json file used by ryandev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_website_json(dataframe, json_file_path):\n",
    "    #TODO: add backup folder with files overwritten\n",
    "    categories_added = 0\n",
    "    categories_ctn = 0\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        places = json.load(file)\n",
    "        for place in places['features']:\n",
    "            if 'category' not in place:\n",
    "                if place['properties']['Title'] in dataframe['name'].values:\n",
    "                    place['properties']['category'] = dataframe[dataframe['name'] == place['properties']['Title']].category.values[0]\n",
    "                    categories_added = categories_added + 1 \n",
    "                    categories_ctn = categories_ctn + 1\n",
    "            else:\n",
    "                categories_ctn = categories_ctn + 1\n",
    "\n",
    "    backup_file('savedPlaces')\n",
    "    with open(json_file_path, 'w') as file:\n",
    "        json.dump(places, file) # will overwrite page\n",
    "    \n",
    "    return f\"Categories added: {categories_added} Total Categories: {categories_ctn}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ea485",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_website_json(df_places, './savedPlaces.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
